[{"content":" Newsletter Subscribe to recieve latest blog posts ","date":"10 October 2024","externalUrl":null,"permalink":"/newsletter/","section":"Welcome to Merox.dev","summary":"\u003ch1 class=\"relative group\"\u003eNewsletter \n    \u003cdiv id=\"newsletter\" class=\"anchor\"\u003e\u003c/div\u003e\n    \n\u003c/h1\u003e\n\u003chr\u003e\n\n\n\u003ch3 class=\"relative group\"\u003eSubscribe to recieve latest blog posts \n    \u003cdiv id=\"subscribe-to-recieve-latest-blog-posts\" class=\"anchor\"\u003e\u003c/div\u003e\n    \n\u003c/h3\u003e\n\u003ccenter\u003e\u003ciframe width=\"540\" height=\"305\" src=\"https://b3fbfc70.sibforms.com/serve/MUIFABCtq4fAbS0WYoJev56fW37uIXJ9tyGgqNG2FTCugb57l6Iywhc0092K2AGL6gLb6roWo5dTGYxjjR8TE3-N5r7nMOx6HszF47ykWkcGtIK0O2LerOjX5wQxMQo2eKjX7zRWTOZ9LK7POceuNJTp-JSvslq33cqbwpTwb7B6r7IZKbPQz3MCIMBKhMDRTM4WHUHTscOohDNF\" frameborder=\"0\" scrolling=\"auto\" allowfullscreen style=\"display: block;margin-left: auto;margin-right: auto;max-width: 100%;\"\u003e\u003c/iframe\u003e\u003c/center\u003e","title":"","type":"page"},{"content":" the most ambitious and challenging project I’ve ever undertaken Image Link Details Status Infrastructure Infrastructure presentation On going... Connectivity Networking setup and maintenance On going... Hypervisors Managing virtualization layers Ready Virtual Machines VMs setup and configuration Ready Docker Container orchestration and management Ready Kubernetes Cluster management On going... Ansible Automation and configuration management Ready Protection Security measures and firewall setup On going... System Monitoring Monitoring tools and alerts Ready ","date":"10 October 2024","externalUrl":null,"permalink":"/laboratory/","section":"Welcome to Merox.dev","summary":"\u003ch2\u003ethe most ambitious and challenging project I’ve ever undertaken\u003c/h3\u003e\n\u003ctable\u003e\n    \u003cthead\u003e\n        \u003ctr\u003e\n            \u003cth\u003eImage\u003c/th\u003e\n            \u003cth\u003eLink\u003c/th\u003e\n            \u003cth\u003eDetails\u003c/th\u003e\n            \u003cth\u003eStatus\u003c/th\u003e\n        \u003c/tr\u003e\n    \u003c/thead\u003e\n    \u003ctbody\u003e\n        \u003ctr\u003e\n            \u003ctd rowspan=3\u003e\u003cimg class=\"customEntitityLogo\" src=\"infra.webp\"/\u003e\u003c/td\u003e\n            \u003ctd rowspan=3\u003e\u003ca href=\"https://docs.merox.dev/homelab/infrastructure/\" target=\"_blank\"\u003eInfrastructure\u003c/a\u003e\u003c/td\u003e\n        \u003c/tr\u003e\n        \u003ctr\u003e\n            \u003ctd\u003eInfrastructure presentation\u003c/td\u003e\n            \u003ctd\u003e\u003cfont color=\"orange\"\u003eOn going...\u003c/font\u003e\u003c/td\u003e\n        \u003c/tr\u003e\n        \u003ctr\u003e\u003c/tr\u003e\n        \u003ctr\u003e\n            \u003ctd\u003e\u003cimg class=\"customEntitityLogo\" src=\"switch.avif\"/\u003e\u003c/td\u003e\n            \u003ctd\u003e\u003ca href=\"https://docs.merox.dev/homelab/connectivity/\" target=\"_blank\"\u003eConnectivity\u003c/a\u003e\u003c/td\u003e\n            \u003ctd\u003eNetworking setup and maintenance\u003c/td\u003e\n            \u003ctd\u003e\u003cfont color=\"orange\"\u003eOn going...\u003c/font\u003e\u003c/td\u003e\n        \u003c/tr\u003e\n        \u003ctr\u003e\n            \u003ctd\u003e\u003cimg class=\"customEntitityLogo\" src=\"proxmox.png\"/\u003e\u003c/td\u003e\n            \u003ctd\u003e\u003ca href=\"https://docs.merox.dev/homelab/hypervisors/\" target=\"_blank\"\u003eHypervisors\u003c/a\u003e\u003c/td\u003e\n            \u003ctd\u003eManaging virtualization layers\u003c/td\u003e\n            \u003ctd\u003e\u003cfont color=\"green\"\u003eReady\u003c/font\u003e\u003c/td\u003e\n        \u003c/tr\u003e\n        \u003ctr\u003e\n            \u003ctd\u003e\u003cimg class=\"customEntitityLogo\" src=\"vms.png\"/\u003e\u003c/td\u003e\n            \u003ctd\u003e\u003ca href=\"https://docs.merox.dev/homelab/virtual-machines/\" target=\"_blank\"\u003eVirtual Machines\u003c/a\u003e\u003c/td\u003e\n            \u003ctd\u003eVMs setup and configuration\u003c/td\u003e\n            \u003ctd\u003e\u003cfont color=\"green\"\u003eReady\u003c/font\u003e\u003c/td\u003e\n        \u003c/tr\u003e\n        \u003ctr\u003e\n            \u003ctd\u003e\u003cimg class=\"customEntitityLogo\" src=\"docker.png\"/\u003e\u003c/td\u003e\n            \u003ctd\u003e\u003ca href=\"https://docs.merox.dev/homelab/docker/\" target=\"_blank\"\u003eDocker\u003c/a\u003e\u003c/td\u003e\n            \u003ctd\u003eContainer orchestration and management\u003c/td\u003e\n            \u003ctd\u003e\u003cfont color=\"green\"\u003eReady\u003c/font\u003e\u003c/td\u003e\n        \u003c/tr\u003e\n        \u003ctr\u003e\n            \u003ctd\u003e\u003cimg class=\"customEntitityLogo\" src=\"kubernetes.svg\"/\u003e\u003c/td\u003e\n            \u003ctd\u003e\u003ca href=\"https://docs.merox.dev/homelab/kubernetes/\" target=\"_blank\"\u003eKubernetes\u003c/a\u003e\u003c/td\u003e\n            \u003ctd\u003eCluster management\u003c/td\u003e\n            \u003ctd\u003e\u003cfont color=\"orange\"\u003eOn going...\u003c/font\u003e\u003c/td\u003e\n        \u003c/tr\u003e\n        \u003ctr\u003e\n            \u003ctd\u003e\u003cimg class=\"customEntitityLogo\" src=\"ansible.svg\"/\u003e\u003c/td\u003e\n            \u003ctd\u003e\u003ca href=\"https://docs.merox.dev/homelab/ansible/\" target=\"_blank\"\u003eAnsible\u003c/a\u003e\u003c/td\u003e\n            \u003ctd\u003eAutomation and configuration management\u003c/td\u003e\n            \u003ctd\u003e\u003cfont color=\"green\"\u003eReady\u003c/font\u003e\u003c/td\u003e\n        \u003c/tr\u003e\n        \u003ctr\u003e\n            \u003ctd\u003e\u003cimg class=\"customEntitityLogo\" src=\"pfsense.png\"/\u003e\u003c/td\u003e\n            \u003ctd\u003e\u003ca href=\"https://docs.merox.dev/homelab/security/\" target=\"_blank\"\u003eProtection\u003c/a\u003e\u003c/td\u003e\n            \u003ctd\u003eSecurity measures and firewall setup\u003c/td\u003e\n            \u003ctd\u003e\u003cfont color=\"orange\"\u003eOn going...\u003c/font\u003e\u003c/td\u003e\n        \u003c/tr\u003e\n        \u003ctr\u003e\n            \u003ctd\u003e\u003cimg class=\"customEntitityLogo\" src=\"prometheus.png\"/\u003e\u003c/td\u003e\n            \u003ctd\u003e\u003ca href=\"https://docs.merox.dev/homelab/monitoring/\" target=\"_blank\"\u003eSystem Monitoring\u003c/a\u003e\u003c/td\u003e\n            \u003ctd\u003eMonitoring tools and alerts\u003c/td\u003e\n            \u003ctd\u003e\u003cfont color=\"green\"\u003eReady\u003c/font\u003e\u003c/td\u003e\n        \u003c/tr\u003e\n    \u003c/tbody\u003e\n\u003c/table\u003e","title":"Homelab","type":"page"},{"content":" Download CV Experience Company Link Role Dates Location Forvia - Hella High Performance Computing System Administrator 2022 - Present Hybrid Timisoara, Romania Dolphost Founder \u0026 System Administrator 2022 - 2024 Online Timisoara, Romania Atos IT Solutions Cybersecurity Engineer 2020 - 2022 Full Remote Timisoara, Romania Netex System Administrator in DC 2018 - 2020 On site Timisoara, Romania Education School Link Degree Date CCNA Cisco Certified Network Associate 2020 Savnet Training Center 2019 West University Of Timisoara Left 2018 Computer Science 2016 ","date":"10 October 2024","externalUrl":null,"permalink":"/resume/","section":"Welcome to Merox.dev","summary":"\u003ca\n  class=\"!rounded-md bg-primary-600 px-4 py-2 !text-neutral !no-underline hover:!bg-primary-500 dark:bg-primary-800 dark:hover:!bg-primary-700\"\n  href=\"/robertmelcher_cv.pdf\"\n  target=\"_self\"\n  \n  role=\"button\"\n\u003e\n  \nDownload CV\n\n\u003c/a\u003e\n\n\n\n\u003ch2 class=\"relative group\"\u003eExperience \n    \u003cdiv id=\"experience\" class=\"anchor\"\u003e\u003c/div\u003e\n    \n\u003c/h2\u003e\n\u003ctable\u003e\n    \u003cthead\u003e\n        \u003ctr\u003e\n            \u003cth\u003eCompany\u003c/th\u003e\n            \u003cth\u003eLink\u003c/th\u003e\n            \u003cth\u003eRole\u003c/th\u003e\n            \u003cth\u003eDates\u003c/th\u003e\n            \u003cth\u003eLocation\u003c/th\u003e\n        \u003c/tr\u003e\n    \u003c/thead\u003e\n    \u003ctbody\u003e\n        \u003ctr\u003e\n            \u003ctd rowspan=3\u003e\u003cimg class=\"customEntitityLogo\" src=\"forvia.png\"/\u003e\u003c/td\u003e\n            \u003ctd rowspan=3\u003e\u003ca href=\"https://www.hella.com/en/\" target=\"_blank\"\u003eForvia - Hella\u003c/a\u003e\u003c/td\u003e\n        \u003c/tr\u003e\n        \u003ctr\u003e\n            \u003ctd\u003eHigh Performance Computing System Administrator\u003c/td\u003e\n            \u003ctd\u003e2022 - Present\u003c/td\u003e\n            \u003ctd\u003eHybrid\u003c/br\u003e Timisoara, Romania\u003c/td\u003e\n        \u003c/tr\u003e\n        \u003ctr\u003e\n        \u003ctr\u003e\n            \u003ctd rowspan=3\u003e\u003cimg class=\"customEntitityLogo\" src=\"dolphost.png\"/\u003e\u003c/td\u003e\n            \u003ctd rowspan=3\u003e\u003ca href=\"https://www.hella.com/en/\" target=\"_blank\"\u003eDolphost\u003c/a\u003e\u003c/td\u003e\n        \u003c/tr\u003e\n        \u003ctr\u003e\n            \u003ctd\u003eFounder \u0026 System Administrator\u003c/td\u003e\n            \u003ctd\u003e2022 - 2024\u003c/td\u003e\n            \u003ctd\u003eOnline\u003c/br\u003e Timisoara, Romania\u003c/td\u003e\n        \u003c/tr\u003e\n        \u003ctr\u003e\n        \u003c/tr\u003e\n        \u003ctr\u003e\n            \u003ctd\u003e\u003cimg class=\"customEntitityLogo\" src=\"atos.png\"/\u003e\u003c/td\u003e\n            \u003ctd\u003e\u003ca href=\"https://atos.net/en/\" target=\"_blank\"\u003eAtos IT Solutions\u003c/a\u003e\u003c/td\u003e\n            \u003ctd\u003eCybersecurity Engineer\u003c/td\u003e\n            \u003ctd\u003e2020 - 2022\u003c/td\u003e\n            \u003ctd\u003eFull Remote \u003c/br\u003e Timisoara, Romania\u003c/td\u003e\n        \u003c/tr\u003e\n        \u003ctr\u003e\n            \u003ctd rowspan=3\u003e\u003cimg class=\"customEntitityLogo\" src=\"netex.svg\"/\u003e\u003c/td\u003e\n            \u003ctd rowspan=3\u003e\u003ca href=\"https://www.netex.de/ro/\" target=\"_blank\"\u003eNetex\u003c/a\u003e\u003c/td\u003e\n        \u003c/tr\u003e\n        \u003ctr\u003e\n            \u003ctd\u003eSystem Administrator in DC\u003c/td\u003e\n            \u003ctd\u003e2018 - 2020\u003c/td\u003e\n            \u003ctd rowspan=2\u003eOn site \u003c/br\u003eTimisoara, Romania\u003c/td\u003e\n        \u003c/tr\u003e\n        \u003ctr\u003e\n        \u003c/tr\u003e\n    \u003c/tbody\u003e\n\u003c/table\u003e\n\u003chr\u003e\n\n\n\u003ch2 class=\"relative group\"\u003eEducation \n    \u003cdiv id=\"education\" class=\"anchor\"\u003e\u003c/div\u003e\n    \n\u003c/h2\u003e\n\u003ctable\u003e\n    \u003cthead\u003e\n        \u003ctr\u003e\n            \u003cth\u003eSchool\u003c/th\u003e\n            \u003cth\u003eLink\u003c/th\u003e\n            \u003cth\u003eDegree\u003c/th\u003e\n            \u003cth\u003eDate\u003c/th\u003e\n        \u003c/tr\u003e\n    \u003c/thead\u003e\n    \u003ctbody\u003e\n        \u003ctr\u003e\n            \u003ctd rowspan=4\u003e\u003cimg class=\"customEntitityLogo\" src=\"cisco.png\"/\u003e\u003c/td\u003e\n            \u003ctd rowspan=4\u003e\u003ca href=\"#\" target=\"_blank\"\u003eCCNA\u003c/a\u003e\u003c/td\u003e\n        \u003c/tr\u003e\n        \u003ctr\u003e\n        \u003c/tr\u003e\n         \u003ctr\u003e\n            \u003ctd\u003eCisco Certified Network Associate\u003c/td\u003e\n            \u003ctd\u003e2020\u003c/td\u003e\n        \u003c/tr\u003e\n        \u003ctr\u003e\n            \u003ctd\u003eSavnet Training Center\u003c/td\u003e\n            \u003ctd\u003e2019\u003c/td\u003e\n        \u003c/tr\u003e\n        \u003ctr\u003e\n            \u003ctd rowspan=3\u003e\u003cimg class=\"customEntitityLogo\" src=\"uvt.png\"/\u003e\u003c/td\u003e\n            \u003ctd rowspan=3\u003e\u003ca href=\"#\" target=\"_blank\"\u003eWest University Of Timisoara\u003c/a\u003e\u003c/td\u003e\n        \u003c/tr\u003e\n        \u003ctr\u003e\n            \u003ctd\u003eLeft\u003c/td\u003e\n            \u003ctd\u003e2018\u003c/td\u003e\n        \u003c/tr\u003e\n        \u003ctr\u003e\n            \u003ctd\u003eComputer Science\u003c/td\u003e\n            \u003ctd\u003e2016\u003c/td\u003e\n        \u003c/tr\u003e\n    \u003c/tbody\u003e\n\u003c/table\u003e","title":"Resume","type":"page"},{"content":"In this section, I proudly present a selection of websites I have developed over the years. Each project reflects my commitment to quality and innovation in web design and development. From personal portfolios to eCommerce platforms, each site showcases my skills in creating user-friendly, visually appealing, and functional online experiences. Explore the screenshots below to see how I bring ideas to life through effective web solutions.\nwordpress / whmcs / hugo / etc. Plative.ro Plative.ro The presentation and download site for a traffic communication app in Romania. Developed by Alex Paczeika, secured by myself.\nAva.delivery ava.delivery An eCommerce site for a client back when dolphost.ro (my web hosting company) existed.\nDolphost dolphost.ro WHMCS Platform - used to sell webhosting \u0026 domains\nRobertMelcher robertmelcher.ro One of my older presentation websites built on WordPress.\n","date":"10 October 2024","externalUrl":null,"permalink":"/websites/","section":"Welcome to Merox.dev","summary":"\u003cp\u003eIn this section, I proudly present a selection of websites I have developed over the years. Each project reflects my commitment to quality and innovation in web design and development. From personal portfolios to eCommerce platforms, each site showcases my skills in creating user-friendly, visually appealing, and functional online experiences. Explore the screenshots below to see how I bring ideas to life through effective web solutions.\u003c/p\u003e","title":"Websites Portofolio","type":"page"},{"content":" Laboratory Curriculum Vitae Hello and welcome! 👋 Explore IT documentation, tech blog posts, and tutorials based on my 10+ years of hands-on experience ⤵","date":"10 October 2024","externalUrl":null,"permalink":"/","section":"Welcome to Merox.dev","summary":"\u003cdiv class=\"flex justify-center py-4\"\u003e\n  \u003ca href=\"/laboratory\" class=\"flex items-center mr-2\"\u003e\n    \u003cbutton\n      id=\"portfolio-button\"\n      class=\"flex items-center px-4 py-2 text-sm !text-neutral !no-underline rounded-md bg-primary-600 hover:bg-primary-500 dark:bg-primary-800 dark:hover:bg-primary-700\"\n    \u003e\n      \u003cspan class=\"mr-2\"\u003e\n        \n        \n          \u003cspan class=\"relative inline-block align-text-bottom icon\"\u003e\n            \u003csvg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 448 512\"\u003e\n        \u003cpath fill=\"currentColor\"  d=\"M159.3 5.4c7.8-7.3 19.9-7.2 27.7 .1c27.6 25.9 53.5 53.8 77.7 84c11-14.4 23.5-30.1 37-42.9c7.9-7.4 20.1-7.4 28 .1c34.6 33 63.9 76.6 84.5 118c20.3 40.8 33.8 82.5 33.8 111.9C448 404.2 348.2 512 224 512C98.4 512 0 404.1 0 276.5c0-38.4 17.8-85.3 45.4-131.7C73.3 97.7 112.7 48.6 159.3 5.4zM225.7 416c25.3 0 47.7-7 68.8-21c42.1-29.4 53.4-88.2 28.1-134.4c-2.8-5.6-5.6-11.2-9.8-16.8l-50.6 58.8s-81.4-103.6-87.1-110.6C133.1 243.8 112 273.2 112 306.8C112 375.4 162.6 416 225.7 416z\"/\u003e\u003c/svg\u003e\n          \u003c/span\u003e\n        \n \u003c!-- Fire icon for Portfolio --\u003e\n      \u003c/span\u003e\n      Laboratory\n    \u003c/button\u003e\n  \u003c/a\u003e\n  \u003ca href=\"/robertmelcher_cv.pdf\" class=\"flex items-center\"\u003e\n    \u003cbutton\n      id=\"cv-button\"\n      class=\"flex items-center px-4 py-2 text-sm !text-neutral !no-underline rounded-md bg-primary-600 hover:bg-primary-500 dark:bg-primary-800 dark:hover:bg-primary-700\"\n    \u003e\n      \u003cspan class=\"mr-2\"\u003e\n        \n        \n          \u003cspan class=\"relative inline-block align-text-bottom icon\"\u003e\n            \u003csvg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 512 512\"\u003e\n        \u003cpath fill=\"currentColor\" d=\"M288 32c0-17.7-14.3-32-32-32s-32 14.3-32 32V274.7l-73.4-73.4c-12.5-12.5-32.8-12.5-45.3 0s-12.5 32.8 0 45.3l128 128c12.5 12.5 32.8 12.5 45.3 0l128-128c12.5-12.5 12.5-32.8 0-45.3s-32.8-12.5-45.3 0L288 274.7V32zM64 352c-35.3 0-64 28.7-64 64v32c0 35.3 28.7 64 64 64H448c35.3 0 64-28.7 64-64V416c0-35.3-28.7-64-64-64H346.5l-45.3 45.3c-25 25-65.5 25-90.5 0L165.5 352H64zM432 456c-13.3 0-24-10.7-24-24s10.7-24 24-24s24 10.7 24 24s-10.7 24-24 24z\"/\u003e\u003c/svg\u003e\n          \u003c/span\u003e\n        \n \u003c!-- Download icon for CV --\u003e\n      \u003c/span\u003e\n      Curriculum Vitae\n    \u003c/button\u003e\n  \u003c/a\u003e\n\u003c/div\u003e\nHello and welcome! 👋 Explore IT documentation, tech blog posts, and tutorials based on my \u003cb\u003e10+ years\u003c/b\u003e of hands-on \u003ci\u003eexperience\u003c/i\u003e ⤵","title":"Welcome to Merox.dev","type":"page"},{"content":" Blog # ","date":"30 September 2024","externalUrl":null,"permalink":"/blog/","section":"","summary":"\u003ch1 class=\"relative group\"\u003eBlog \n    \u003cdiv id=\"blog\" class=\"anchor\"\u003e\u003c/div\u003e\n    \n    \u003cspan\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\n            style=\"text-decoration-line: none !important;\" href=\"#blog\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\n    \u003c/span\u003e        \n    \n\u003c/h1\u003e\n\u003chr\u003e","title":"","type":"blog"},{"content":"","date":"30 September 2024","externalUrl":null,"permalink":"/tags/alexa/","section":"Tags","summary":"","title":"Alexa","type":"tags"},{"content":"","date":"30 September 2024","externalUrl":null,"permalink":"/categories/","section":"Categories","summary":"","title":"Categories","type":"categories"},{"content":"","date":"30 September 2024","externalUrl":null,"permalink":"/tags/homeassistant/","section":"Tags","summary":"","title":"Homeassistant","type":"tags"},{"content":"","date":"30 September 2024","externalUrl":null,"permalink":"/categories/server/","section":"Categories","summary":"","title":"Server","type":"categories"},{"content":"What started as a simple wish to control lights using my phone quickly turned into a fully integrated smart home setup. I’ve always been a bit lazy when it comes to getting up to switch things off manually, but once I discovered the potential of smart devices like Amazon Alexa and Home Assistant, I was hooked. Over time, I’ve expanded the system to include a wide range of devices that automate my entire home.\nDevices I Use # In my smart home setup, I’ve integrated several key devices:\nAmazon Alexa: I use Alexa in every room (living room, bedroom, kitchen) to control most devices via voice commands. Home Assistant: Running on a Dell server through a VM, Home Assistant is the central brain of my setup, managing more complex automations and scripts. Broadlink RM4 Pro: This acts as a bridge for RF and IR devices, allowing me to control roller blinds and non-smart appliances. Philips Hue \u0026amp; Goove Lights: These add mood lighting, often synchronized with specific routines like \u0026ldquo;movie time\u0026rdquo;. Roborock Vacuum, Resideo Thermostat, and air conditioning units. Smart Roller Blinds: Controlled through Broadlink using RF signals. In the near future, I plan to add cameras and a Yale smart lock.\nAlexa and Home Assistant # Initially, Alexa controlled most of the devices, but once I introduced Home Assistant, things got even more flexible. I now have full automation based on my location, weather conditions, and custom scripts. For example, when I leave the house, motion sensors activate, and all roller blinds close automatically. When I return, the system opens the blinds, adjusts the temperature based on the outside weather, and even turns on night lights to guide me through the dark.\nExample Automations # Morning and Night Routines # One of the key routines I rely on is Good Morning and Good Night, which create a seamless transition from sleep to waking and vice versa. These routines handle:\nOpening the blinds to a certain level in the morning to let in natural light. Shutting down all lights and closing the blinds in the evening to create the perfect environment for sleep. This automation has made mornings feel more natural and relaxing, and night routines are much more consistent without having to remember to switch everything off.\nMovie and Gaming Time # When it’s time for a movie or gaming session, I have created automations to handle the ambiance and setup:\nMovie Time: The blinds in the living room close, the TV turns on and switches to Netflix, the soundbar is set to a specific sound mode, and the air conditioning turns on if it’s summer. Additionally, the ambient lighting around the TV adjusts to create the perfect movie-watching environment. Gaming Time: Similar to Movie Time, but the TV connects to the PlayStation 5, and the lights adjust for a more immersive experience. Alexa - Routine1 Alexa - Routine2 Philips Hue Alexa, movie time\nSecurity Setup # For security, my motion sensors automatically trigger when I leave, and I receive notifications via Alexa and Home Assistant if anything unusual happens. For instance, any significant changes in room temperature or other unexpected events will prompt alerts, helping me stay in control even when I’m away.\nTutorial: Integrating Broadlink with Alexa \u0026amp; RF Learning # Here’s a simple tutorial on how I used Broadlink RM4 Pro to integrate RF devices like my roller blinds with Alexa.\nStep 1: Set Up Broadlink RM4 Pro # Download the Broadlink app and follow the steps to connect the RM4 Pro to your Wi-Fi. Register an account and add the RM4 Pro device in the app. Step 2: Learn RF Signals # Select Add Remote in the Broadlink app, and choose \u0026ldquo;RF Appliance\u0026rdquo;. Use your original remote for the roller blinds, press the corresponding button while the app is in Learning Mode, and save the learned code. Test the new button to make sure it controls the blinds. Step 3: Connect Broadlink to Alexa # In the Alexa app, enable the Broadlink skill. Link your Broadlink account and let Alexa discover your RF devices. Now, you can use voice commands like, “Alexa, close the blinds,” and it will work seamlessly.\nBroadlink - Dashboard Broadlink - IR/RF Broadlink - Learning Challenges and Advanced Automations # The Most Challenging Part: Running Linux Scripts # One of the more challenging aspects was getting Home Assistant to correctly execute Linux scripts based on my GPS location. Using bash commands, I created scripts that adjust server fan speeds based on external temperatures when I leave or return home.\nFor example:\nWhen I’m away, the server fan speeds up to keep the system cool. Lights automatically adjust, and blinds close. When I come back, the system reverses these actions. /root/homeassistant/configuration.yaml #!/bin/bash # Adjust server fan speed based on external temperature shell_command: set_fans_home: \u0026#39;ssh -i /config/ssh/id_rsa -o StrictHostKeyChecking=no root@10.10.10.10 /usr/bin/ipmitool -I lanplus -H 10.10.10.200 -U root -P SuperSecretPassword raw 0x30 0x30 0x02 0xff 0x14\u0026#39; set_fans_away: \u0026#39;ssh -i /config/ssh/id_rsa -o StrictHostKeyChecking=no root@10.10.10.10 /usr/bin/ipmitool -I lanplus -H 10.10.10.200 -U root -P SuperSecretPassword raw 0x30 0x30 0x02 0xff 0x28\u0026#39; Future Plans # In the near future, I plan to integrate more advanced routines based on my location and possibly automate the Yale smart lock to engage whenever I leave home. The ability to do this with a combination of Alexa and Home Assistant makes the whole process incredibly smooth.\nMore automations # Below, you can see more simple automations videos from my smart home Balcony lights Roborock start cleaning Hue motion sensor\nConclusion # Building a smart home is an ongoing project, and with tools like Broadlink, Alexa, and Home Assistant, it’s more accessible than ever. Whether you’re just starting or already have a setup, there’s always room for improvement and more efficient automation. The beauty of smart home devices lies in how they can adapt to your personal routines and preferences, making everyday life a little easier.\nCredits # 📹 Smart Home Solver - YouTube Channel. 📹 Grayson Adams - YouTube Channel. 📹 Smart Home Junkie - YouTube Channel. 📹 Everything Smart Home - YouTube Channel. ","date":"30 September 2024","externalUrl":null,"permalink":"/blog/smarthome-journey/","section":"","summary":"What started as a simple wish to control lights using my phone quickly turned into a fully integrated smart home setup. I’ve always been a bit lazy when it comes to getting up\u0026hellip;","title":"Smart Home Journey","type":"blog"},{"content":"","date":"30 September 2024","externalUrl":null,"permalink":"/categories/smarthome/","section":"Categories","summary":"","title":"Smarthome","type":"categories"},{"content":"","date":"30 September 2024","externalUrl":null,"permalink":"/tags/","section":"Tags","summary":"","title":"Tags","type":"tags"},{"content":"","date":"30 September 2024","externalUrl":null,"permalink":"/tags/tutorial/","section":"Tags","summary":"","title":"Tutorial","type":"tags"},{"content":"","date":"16 August 2024","externalUrl":null,"permalink":"/categories/ai/","section":"Categories","summary":"","title":"AI","type":"categories"},{"content":"","date":"16 August 2024","externalUrl":null,"permalink":"/tags/opensource/","section":"Tags","summary":"","title":"Opensource","type":"tags"},{"content":"Recently, I started exploring the field of AI to better understand what my home lab setup is capable of. This time, I used a Dell PowerEdge R720 server, equipped with 192 GB of RAM, dual 6-core CPUs (24 threads), and no GPU, to familiarize myself with various AI tools. Having done some investigation into this matter, three major tools attracted my attention-Stable Diffusion, OpenWebUI and Ollama. Each tool has unique features while together they make up a functional AI environment for me to play around with.\nBelow are brief descriptions of the tools:\nStable Diffusion: A model that generates high-quality images from text prompts, ideal for exploring AI-generated art. OpenWebUI: An intuitive interface that makes it easier to manage and interact with AI models. Ollama: A versatile AI framework designed for seamless integration and reliable performance. In this article, I will go over how I set these tools up on my server as well as their configurations. The difficulties that were there , the solutions I found and useful tips that may be helpful when working under similar conditions will also be shared. Even though still new in Artificial Intelligence systems at least my experience can be of great help to others who may want to start too.\nSetting Up Ollama: My First Step into AI # The first tool I tackled was Ollama. After doing some research, it seemed like a good starting point because of its straightforward setup and broad compatibility. Ollama is a flexible AI framework that can be installed on all major platforms—Linux, MacOS, and Windows—which made it accessible no matter what system you’re running. Plus, it provides a solid foundation for further AI experiments, which is exactly what I needed for my home lab.\nInstalling Ollama on Linux # I began by setting up Ollama on a virtual machine running Ubuntu 22.04 in my Proxmox environment. I allocated 20 cores and 64GB of RAM to this VM to ensure smooth performance during testing.\nTo install Ollama, I used the following command:\ncurl -fsSL https://ollama.com/install.sh | sh Downloading the Llama3 Model # Once the installation was complete, the next step was to download a model to work with. I chose the Llama3 model, which is known for its performance in various AI tasks. To download it, I ran the command:\nollama pull llama3 Running the Llama3 Model # ollama run llama3 example \u0026ldquo;llama3 cli example\u0026rdquo; # How does the concept of time dilation in Interstellar relate to Einstein\u0026rsquo;s theory of relativity?\nThe concept of time dilation in Interstellar is directly related to Albert Einstein\u0026rsquo;s theory of special relativity, specifically the concept of time dilation. Here\u0026rsquo;s how:\nIn the movie, a wormhole allows Cooper\u0026rsquo;s spaceship to travel at incredibly high speeds, approaching relativistic velocities. As they approach the speed of light (0.99c), time appears to slow down for them relative to Earth. This is precisely what Einstein predicted in his theory\u0026hellip;\u0026quot;\nSetting Up Stable Diffusion # Stable Diffusion is a powerful model for generating high-quality images from text prompts. Setting it up on my Ubuntu 22.04 VM was quite straightforward thanks to the clear installation guide provided in the official GitHub repository.\nInstallation Steps # Here’s a summary of the steps I followed to install Stable Diffusion:\nInstall the Dependencies # Depending on your Linux distribution, use one of the following commands to install the necessary dependencies:\nDebian-based (e.g., Ubuntu):\nsudo apt install wget git python3 python3-venv libgl1 libglib2.0-0 Red Hat-based:\nsudo dnf install wget git python3 gperftools-libs libglvnd-glx openSUSE-based:\nsudo zypper install wget git python3 libtcmalloc4 libglvnd Download the Web UI Script # Navigate to the directory where you want to install Stable Diffusion and execute the following command:\nwget -q https://raw.githubusercontent.com/AUTOMATIC1111/stable-diffusion-webui/master/webui.sh Run the WebUI Script # ./webui.sh Configure the webui-user.sh File # Since my server does not have a GPU, I needed to adapt the webui-user.sh file to optimize performance for CPU usage. Specifically, I added the following line to configure the environment for CPU-only operation:\nexport COMMANDLINE_ARGS=\u0026#34;--lowvram --precision full --no-half --skip-torch-cuda-test\u0026#34; \u0026ndash;lowvram: Reduces memory usage to accommodate systems with limited GPU memory.\n\u0026ndash;precision full: Ensures full precision calculations, useful for CPU processing.\n\u0026ndash;no-half: Disables half-precision calculations to avoid potential issues on CPUs.\n\u0026ndash;skip-torch-cuda-test: Skips tests related to CUDA, which is irrelevant on systems without GPUs.\nStart the Web UI # By default, running the webui.sh command will start the server and bind it to localhost (127.0.0.1). To allow access from other interfaces (useful for integration with OpenWebUI), use the \u0026ndash;listen parameter:\n./webui.sh --listen This command makes the server accessible on all network interfaces at port 7860 (0.0.0.0:7860).\nStable Diffusion Webpage Setting Up OpenWebUI # With Ollama and Stable Diffusion installed and configured, the next step is to centralize these tools into a single, user-friendly interface. OpenWebUI provides a cohesive platform to interact with your AI models, similar to ChatGPT.\nInstallation Steps # Setting up OpenWebUI is probably the easiest and quickest part of this tutorial, thanks to its well-organized and straightforward documentation. You can deploy OpenWebUI using Docker, which simplifies the installation process.\nInstallation with Default Configuration # If Ollama is running on the same server as OpenWebUI, use the following Docker command:\ndocker run -d -p 3000:8080 --add-host=host.docker.internal:host-gateway -v open-webui:/app/backend/data --name open-webui --restart always ghcr.io/open-webui/open-webui:main If Ollama is hosted on a different server, you need to specify the URL of the Ollama server:\ndocker run -d -p 3000:8080 -e OLLAMA_BASE_URL=https://example.com -v open-webui:/app/backend/data --name open-webui --restart always ghcr.io/open-webui/open-webui:main For running OpenWebUI with Nvidia GPU support, use this command:\ndocker run -d -p 3000:8080 --gpus all --add-host=host.docker.internal:host-gateway -v open-webui:/app/backend/data --name open-webui --restart always ghcr.io/open-webui/open-webui:cuda Integrating Ollama and Stable Diffusion # Once OpenWebUI is up and running, the next step is to integrate it with Ollama and Stable Diffusion via API connections.\nConnecting Ollama # Open your browser and navigate to: # OpenWebUI Admin Settings # Click to collapse 1.1 http://ip_server_openwebui:3000/admin/settings/\n1.2 Go to Models -\u0026gt; Manage Ollama Models.\n1.3 Enter the URL of your Ollama server\nAdmin Settings If you\u0026rsquo;re running Ollama and OpenWebUI on the same server, this step might be auto-filled.\nConnecting Stable Diffusion # Click to collapse 1.1 Go to Images and find the AUTOMATIC1111 Base URL field.\n1.2 Enter the URL of your Stable Diffusion server:\n1.3 Press the refresh check button next to the URL to verify the connection with the Stable Diffusion server. If everything is working correctly, click Save.\n1.4 You can now adjust the parameters under Set Default Model according to your needs.\nAdmin Settings Voilà!\nWith OpenWebUI, Ollama, and Stable Diffusion all integrated, you now have a unified interface to interact with your AI models, making it easier to manage and utilize these powerful tools in your home lab.\nConclusion # As I continue to explore and build my AI environment, I plan to enhance my setup with a dedicated GPU in the near future. I\u0026rsquo;m considering an NVIDIA TESLA P40, which should significantly boost performance and allow for more efficient processing. Once I have this upgrade in place, I\u0026rsquo;ll provide updated information and tips on configuring AI tools with GPU support.\nCurrently, with my setup of dual Intel Xeon E5-2620 v2 CPUs at 2.10GHz, the performance is functional but not particularly fast. The experience has been quite interesting, offering valuable insights into AI integration and usage. Here are some performance metrics from my current setup with Ollama and Stable Diffusion:\nResponse Token/s: 0.46 Prompt Token/s: 1.99 Total Duration: 1072376.46 ms (approximately 17 minutes 52 seconds) Load Duration: 61347.1 ms Prompt Eval Count: 33 Prompt Eval Duration: 16571.72 ms Eval Count: 457 Eval Duration: 994411.07 ms These numbers illustrate the impact of running AI models on a CPU-only configuration. Despite the slower performance, the journey has been rewarding and informative.\nThank you for following along with my AI setup journey. I hope these insights and steps will be useful for anyone starting with AI tools in a similar environment. If you have any questions or need further assistance, feel free to reach out!\nFor those interested in GPU setups, here are some useful resources to help with GPU configuration:\nCredits # 📹 TechnoTim - AI Setup. 🐙 Sean Zheng - Running Llama 3 Model with NVIDIA GPU. ","date":"16 August 2024","externalUrl":null,"permalink":"/blog/run-ai-at-home/","section":"","summary":"In this article, I will go over how I set these tools up on my server as well as their configurations. The difficulties that were there , the solutions I found and useful tips\u0026hellip;","title":"Setting up your own AI at home","type":"blog"},{"content":"","date":"13 July 2024","externalUrl":null,"permalink":"/tags/home/","section":"Tags","summary":"","title":"Home","type":"tags"},{"content":"","date":"13 July 2024","externalUrl":null,"permalink":"/categories/installation/","section":"Categories","summary":"","title":"Installation","type":"categories"},{"content":"I recently stumbled upon an incredible deal for the Dell PowerEdge R720 server. This powerhouse boasts impressive specifications:\nTechnical Specifications # Server Model: Dell PowerEdge R720 RAM: 192GB Processors: Dual 6-core CPUs with Hyper-Threading (24 threads) iDRAC Controller: iDRAC7 Enterprise Storage: 2 x 2TB SSD \u0026amp; 6 x 300GB SAS drives at 6Gb/s This article covers my journey of integrating this powerhouse into my home lab setup.\nDelivery and Initial Setup # The server arrived in good condition, but I encountered an issue where the front backplane wasn\u0026rsquo;t connected because the included mini SAS cable was too short. I had to search online to find a 59cm mini SAS cable long enough to connect the backplane to the motherboard.\nI was lucky and I found this cable pretty quick thanks to this company in Romania:\ni-Service - MiniSAS\nConfiguring the Cooling System with IPMItool # Managing server cooling effectively is crucial for optimal performance and longevity. Using IPMItool, I was able to configure the fans to balance between cooling efficiency and noise levels. Below are the steps and commands I used:\nInstall IPMItool: # sudo apt-get install ipmitool Enable/disable manual fan control # Enable # ipmitool -I lanplus -H ip_addr -U username -P password raw 0x30 0x30 0x01 0x00 Disable # ipmitool -I lanplus -H ip_addr -U username -P password raw 0x30 0x30 0x01 0x01 Set fan speed # ipmitool -I lanplus -H ip_addr -U username -P password raw 0x30 0x30 0x02 0xff 0x14 Consult the table to adapt the speed to your needs # Procent Hexadecimal RPM 10% 0xA ~3,300 RPM 16% 0x10 ~3,900 RPM 20% 0x14 ~4,000 RPM 25% 0x19 ~4,700 RPM 30% 0x1E ~5,400 RPM 40% 0x28 ~7,300 RPM 50% 0x32 ~8,000 RPM 60% 0x3C ~9,400 RPM 70% 0x46 ~10,800 RPM 80% 0x50 ~12,100 RPM 90% 0x5A ~13,300 RPM 100% 0x64 15,000 RPM Monitor fan status # ipmitool sensor | grep -i fan Fine-tuning the fan speeds can drastically reduce the noise levels in a home lab environment, which is often a crucial consideration compared to a data center where noise is less of an issue. Upgrading Firmware via UpdateYODell.net # Keeping firmware up-to-date is essential for security and performance. I upgraded my R720\u0026rsquo;s firmware using the resources available on UpdateYODell.net. Here’s a step-by-step guide:\nIdentify Your Server’s Generation: # Visit Wikipedia\u0026rsquo;s Dell PowerEdge page to find your server model and its generation.\nConfigure iDRAC for FTP Update: # Access the iDRAC web interface. Navigate to Maintenance \u0026gt; System Update. Select FTP as the update method and use next settings: Address - ftp.updateyodell.net User Name - dell Password - calvin Path - g11, g12(dell r720), g13, or g14 Click Check for Updates and proceed with the upgrade. Updating the firmware ensures that the server runs smoothly and is protected against known vulnerabilities. It can also bring new features and improvements to your system, which is particularly beneficial in a home lab setting where experimentation and learning are key. Migrating Proxmox Cluster # Migrating my Proxmox cluster to the new server was simplified by utilizing an NFS share on my Synology DS223 in the homelab. Here’s how I did it:\nMount NFS Share on New Proxmox Server: # mount -t nfs \u0026lt;synology_ip\u0026gt;:/path/to/nfs /mnt/pve/nfs Restore VMs from NFS: # pct restore \u0026lt;vmid\u0026gt; /mnt/pve/nfs/dump/dump.tar Benefits of Using NFS with Proxmox: Using an NFS share for backups and migrations offers several advantages:\nSimplicity: Easy to set up and manage. Efficiency: Fast transfer speeds, especially with a dedicated network. Flexibility: Can easily expand storage as needed. Storage Configuration # In the Dell R720, I configured the storage with two 2TB SSDs in RAID 1 for the operating system and primary applications, and six 300GB SAS drives in RAID 10 for data storage. This setup offers a great balance between performance, redundancy, and storage capacity.\nBenefits of This Storage Setup: # RAID 1 for SSDs: Provides redundancy, ensuring that the OS and critical applications are safe even if one SSD fails. RAID 10 for SAS Drives: Combines the speed benefits of RAID 0 with the redundancy of RAID 1, offering fast read/write speeds and protection against drive failures. Integrating with UPS Using PowerPanel # To protect the server from power outages, integrating it with a UPS (Uninterruptible Power Supply) was crucial. Instead of using NUT, I opted for PowerPanel:\nInstall PowerPanel: # Download and install the PowerPanel software from the CyberPower website.\nDownload # curl -o cyberpowerpowerpanel.deb https://www.cyberpower.com/tw/en/File/GetFileSampleByType?fileId=SU-18070001-06\u0026amp;fileType=Download%20Center\u0026amp;fileSubType=FileOriginal Install # dpkg -i cyberpowerpowerpanel.deb Configure PowerPanel: # I configured PowerPanel in my environment with the following command:\npwrstat -lowbatt -runtime 300 -capacity 35 -active on -cmd /etc/pwrstatd-lowbatt.sh -duration 1 -shutdown on Explanation of the Command: # -lowbatt: Triggers the action when the battery is low. -runtime 300: Triggers the action when the UPS runtime drops below 300 seconds. -capacity 35: Triggers the action when the battery capacity drops below 35%. -active on: Enables the action. -cmd /etc/pwrstatd-lowbatt.sh: Executes the specified script when the condition is met. -duration 1: Specifies the duration in minutes to wait before executing the shutdown. -shutdown on: Initiates a system shutdown when the condition is met. This configuration ensures that my server shuts down gracefully in the event of a power outage, protecting data integrity and preventing hardware damage.\nMonitoring and Management # For monitoring the server\u0026rsquo;s performance and health, I use a combination of Prometheus and Grafana. These tools provide detailed metrics and visualizations, allowing me to keep an eye on resource usage, temperatures, and potential issues.\nBackup Strategy # Having a robust backup strategy is crucial in any lab environment. I use Proxmox\u0026rsquo;s built-in backup tools to create regular snapshots of my VMs, which are then stored on the NFS share. This ensures that I can quickly recover from any data loss or corruption.\nConclusion # Setting up the Dell R720 in my home lab has been an exciting journey. From configuring cooling and upgrading firmware to migrating my Proxmox cluster and integrating with a UPS, every step has enhanced my lab\u0026rsquo;s performance and reliability. Additionally, the advanced network and storage configurations have made my setup more robust and efficient. I hope this guide helps you in your home lab endeavors.\nStay tuned for more updates and experiments in my home lab! Credits # 📹 Tutorial - Dell \u0026amp; HP Server Manual Fan Control. 🐙 Kenneth Finnegan - Update your old ass Dell servers. 🖥️ NOiSEA - Cyberpower power panel. ","date":"13 July 2024","externalUrl":null,"permalink":"/blog/dell-r720/","section":"","summary":"I recently stumbled upon an incredible deal for the Dell PowerEdge R720 server. This powerhouse boasts impressive specifications\u0026hellip;","title":"Setting Up Dell R720 Server in the Home Lab","type":"blog"},{"content":"","date":"1 July 2024","externalUrl":null,"permalink":"/authors/","section":"Authors","summary":"","title":"Authors","type":"authors"},{"content":"","date":"1 July 2024","externalUrl":null,"permalink":"/authors/merox/","section":"Authors","summary":"","title":"Merox","type":"authors"},{"content":" Seasoned System Administrator and Cybersecurity Engineer, with a profound passion for Linux, Networking, and Security. My career has been a journey through challenging roles, where I've developed a blend of technical prowess and strategic insight. Why merox.dev? # Well, \u0026ldquo;merox.dev\u0026rdquo; does have a personal touch and a little history. It\u0026rsquo;s a fusion of elements that reflect both my background and interests:\nMERO: The first part of the name comes from combining the first letters of my name, \u0026ldquo;ME\u0026rdquo; for Melcher and \u0026ldquo;RO\u0026rdquo; for Robert. This is sort of a wink toward my identity and a touch of personality within the work I do.\nThe \u0026ldquo;X\u0026rdquo; in \u0026ldquo;merox\u0026rdquo; adds some mystery and adaptability to the name. My username was originally based on hexadecimal notation—\u0026ldquo;mer0x39,\u0026rdquo; where \u0026ldquo;0x39\u0026rdquo; is the number 57, essentially the day and month of my birthday.\nThe idea of merox.dev was to create a full-scale repository including all my experience and knowledge gained within the last ten years working in IT. This site is my personal archive, containing from complex technical solutions to many experiences obtained during projects. A blog section is the newest part where I share my thoughts, trends, and updates on what\u0026rsquo;s new in tech.\nIn essence, merox.dev represents a bit of my path, expertise, and passion for IT; it provides useful resources and information to others within this industry.\nProfessional Journey # Throughout my career, I\u0026rsquo;ve had the privilege of working with industry leaders such as Hella, Atos, and Netex. These experiences have shaped my approach to IT and cybersecurity, allowing me to:\nSpearhead cutting-edge cybersecurity initiatives Optimize complex server environments Align IT strategies with organizational goals Key Achievements # 🐳 Successfully dockerized and migrated a Puppet server from a virtual machine to a Kubernetes cluster, enhancing scalability and resource efficiency 🖥️ Led the migration and creation of Forescout policies from Windows 7 to Windows 10, ensuring seamless transition and improved security posture 🛡️ Implemented robust security measures across various network devices including Palo Alto, Fortigate, Cisco, and McAfee, significantly enhancing the organization\u0026rsquo;s cybersecurity infrastructure 💾 Designed and implemented a comprehensive backup solution using Bareos for an entire datacenter, ensuring data integrity and disaster recovery readiness 🌐 Leveraged CCNA expertise to design and implement complex network infrastructures, optimizing performance and security 🚀 Orchestrated multiple infrastructure modernization projects, improving system reliability and operational efficiency Core Competencies # Linux Systems Networking Security System optimization Infrastructure design Threat analysis Shell scripting Network protocols Penetration testing Performance tuning Troubleshooting Security audits Philosophy \u0026amp; Continuous Learning # I believe in the power of continuous learning and staying ahead of the technological curve. My approach involves:\nConstantly exploring emerging technologies Participating in cybersecurity communities and forums Sharing knowledge through mentoring and tech talks Let\u0026rsquo;s Connect # Interested in collaborating or learning more about my work? I\u0026rsquo;m always open to discussing new opportunities and ideas in the world of IT and cybersecurity.\n","date":"1 July 2024","externalUrl":null,"permalink":"/about/","section":"Welcome to Merox.dev","summary":"Seasoned System Administrator and Cybersecurity Engineer, with a profound passion for Linux, Networking, and Security.","title":"Who's Merox?","type":"page"},{"content":"","date":"6 April 2024","externalUrl":null,"permalink":"/tags/network/","section":"Tags","summary":"","title":"Network","type":"tags"},{"content":"","date":"6 April 2024","externalUrl":null,"permalink":"/categories/networking/","section":"Categories","summary":"","title":"Networking","type":"categories"},{"content":"I\u0026rsquo;ve decided to implement monitoring for my homelab through a cloud virtual machine.\nAs cloud provider I\u0026rsquo;ve opted for Hetzner, but more on that in a future post.\nTo enhance the security of this setup, I\u0026rsquo;ve chosen to establish the cloud VM from Hetzner as the single entry point to my infrastructure. For this purpose, I\u0026rsquo;ve opted to use Tailscale for tunneling, not only for client-to-site but also for site-to-site connectivity.\nInformations provided by tailscale:\n\u0026ldquo;Use site-to-site layer 3 (L3) networking to connect two subnets on your Tailscale network with each other. The two subnets are each required to provide a subnet router but their devices do not need to install Tailscale. This scenario applies to Linux subnet routers only.\u0026rdquo; This scenario will not work on subnets with overlapping CIDR ranges, nor with 4via6 subnet routing. In my case, there are two private subnets without any connectivity between them. Subnet 1 - Homelab: 10.57.57.0/24\nSubnet 2 - Cloudlab: 192.168.57.0/24\nIP addresses of the routers for each subnet: Subnet 1 -\u0026gt; 10.57.57.1 ( pfSense )\nSubnet 2 -\u0026gt; 192.168.57.254 ( Linux VM )\nSetting up Tailscale site-to-site on pfSense Subnet I # Let\u0026rsquo;s dive into the configuration. Due to pfSense being based on FreeBSD and Tailscale not offering as much support for pfSense as for other platforms, this configuration is a bit trickier. But let\u0026rsquo;s see how it looks.\nInstall tailscale on pfSense # Navigate to Package Manager: Go to System \u0026gt; Package Manager in the pfSense web interface.\nInstall Package: Click on the \u0026ldquo;Available Packages\u0026rdquo; tab. Search for tailscale and click \u0026ldquo;Install\u0026rdquo;.\nConfigure tailscale on pfSense # Navigate to Tailscale: VPN -\u0026gt; Tailscale\nAuthentication # Copy auth-key from https://login.tailscale.com/admin/settings/keys Generate Auth keys # Check: \u0026ldquo;Enable tailscale\u0026rdquo; Listen port: leave it as it is Check: Accept Subnet Routes Optional check: Advertise Exit Node Advertised Routes: 10.57.57.0/24 Tricky part: Outbound NAT Rules # Navigate to Firewall-\u0026gt; NAT-\u0026gt; Outbound\nMake sure Outbound NAT Mode is configured to be configured as # Hybrid Outbound NAT\nCreate next manual mapping # Interface: Tailscale Address Family: IPV4+IPV6 Protocol: Any Source Network or Alias: 10.57.57.0/24 Destination: Any This part is broken from last update [ 23.09.1 ] so NAT Alias is missing. Workaround:\nTranslation section:\nAddress: Network or Alias Put the tailscale ip address 100.xx.xx.xx/32\nThis is how should look like:\nConfigure tailscale site-to-site on Linux VM Subnet II # Install tailscale and activate routing: # 1 curl -sSL https://tailscale.com/install.sh | sh #Install tailscale 2 echo \u0026#39;net.ipv4.ip_forward = 1\u0026#39; | sudo tee -a /etc/sysctl.conf #Activate routing for IPv4 3 echo \u0026#39;net.ipv6.conf.all.forwarding = 1\u0026#39; | sudo tee -a /etc/sysctl.conf #Activate routing for IPv6 4 sudo sysctl -p /etc/sysctl.conf # Apply routing configuration at kernel level On the 192.168.57.254 device, advertise routes for 192.168.57.0/24: # 1 tailscale up --advertise-routes=192.168.57.0/24 --snat-subnet-routes=false --accept-routes Command explained:\n\u0026ndash;advertise-routes: Exposes the physical subnet routes to your entire Tailscale network.\n\u0026ndash;snat-subnet-routes=false: Disables source NAT. In normal operations, a subnet device will see the traffic originating from the subnet router. This simplifies routing, but does not allow traversing multiple networks. By disabling source NAT, the end machine sees the LAN IP address of the originating machine as the source.\n\u0026ndash;accept-routes: Accepts the advertised route of the other subnet router, as well as any other nodes that are subnet routers.\nEnable subnet routes from the admin console # This step is not required if using autoApprovers. Open the Machines page of the admin console, and locate the devices that you configured as subnet routers. You can look for the Subnets badge in the machines list, or use the property:subnet filter to see all devices advertising subnet routes. For each device that you need to approve, click the ellipsis icon menu at the end of the table, and select Edit route settings. In the Edit route settings panel, approve the device.\nThe Tailscale side of the routing is complete. Credits # 📝 Tailscale - Seamless networking for secure connections. 📹 Christian McDonald - YouTube Channel. ","date":"6 April 2024","externalUrl":null,"permalink":"/blog/tailscale-site-to-site/","section":"","summary":"I\u0026rsquo;ve decided to implement monitoring for my homelab through a cloud virtual machine. As cloud provider I\u0026rsquo;ve opted for Hetzner\u0026hellip;","title":"Tailscale site-to-site pfSense - Linux","type":"blog"},{"content":"For a long time, I\u0026rsquo;ve been on the hunt for a comprehensive and well-crafted tutorial to deploy a media server on my Kubernetes cluster. This media server stack includes Jellyfin, Radarr, Sonarr, Jackett, and qBittorrent. Let\u0026rsquo;s briefly dive into what each component brings to our setup\nApplication Description Jellyfin An open-source media system that provides a way to manage and stream your media library across various devices. Radarr A movie collection manager for Usenet and BitTorrent users. It automates the process of searching for movies, downloading, and managing your movie library. Sonarr Similar to Radarr but for TV shows. It keeps track of your series, downloads new episodes, and manages your collection with ease. Jackett Acts as a proxy server, translating queries from other apps (like Sonarr or Radarr) into queries that can be understood by a wide array of torrent search engines. qBittorrent A powerful BitTorrent client that handles your downloads. Paired with Jackett, it streamlines finding and downloading media content. Gluetun A lightweight, open-source VPN client for Docker environments, supporting multiple VPN providers to secure and manage internet connections across containerized applications. It ensures privacy and seamless network security with easy configuration and integration. The configuration for these applications is hosted on Longhorn storage, ensuring resilience and ease of management, while the media (movies, shows, books, etc.) is stored on a Synology NAS DS223. The NAS location is utilized as a Persistent Volume (PV) through NFS 4.1 by Kubernetes.\nIn this tutorial, you\u0026rsquo;ll find the Kubernetes configuration for each necessary component to set up, install, and secure each service used by the media server.\nSynology NAS NFS Setup for Kubernetes # If you use Synology NAS, this is the rule I created for my NFS share which will be mounted on kubernetes side. Let\u0026rsquo;s start step by step.\nConfiguring PVC and PV for NFS Share # Media # Create nfs-media-pv-and-pvc.yaml:\n1apiVersion: v1 2kind: PersistentVolume 3metadata: 4 name: jellyfin-videos 5spec: 6 capacity: 7 storage: 400Gi 8 accessModes: 9 - ReadWriteOnce 10 nfs: 11 path: /volume1/server/k3s/media 12 server: storage.merox.cloud 13 persistentVolumeReclaimPolicy: Retain 14 mountOptions: 15 - hard 16 - nfsvers=3 17 storageClassName: \u0026#34;\u0026#34; 18# Persistent Volume spec including capacity, access modes, NFS path, and server details follow 19--- 20apiVersion: v1 21kind: PersistentVolumeClaim 22metadata: 23 name: jellyfin-videos 24 namespace: media 25spec: 26 accessModes: 27 - ReadWriteOnce 28 resources: 29 requests: 30 storage: 400Gi 31 volumeName: jellyfin-videos 32 storageClassName: \u0026#34;\u0026#34; 33# Persistent Volume Claim spec including access modes, resources requests, and storage class name follow Apply with:\nkubectl apply -f nfs-media-pv-and-pvc.yaml Download # Create nfs-download-pv-and-pvc.yaml:\n1apiVersion: v1 2kind: PersistentVolume 3metadata: 4 name: qbitt-download 5spec: 6 capacity: 7 storage: 400Gi 8 accessModes: 9 - ReadWriteOnce 10 nfs: 11 path: /volume1/server/k3s/media/download 12 server: storage.merox.cloud 13 persistentVolumeReclaimPolicy: Retain 14 mountOptions: 15 - hard 16 - nfsvers=3 17 storageClassName: \u0026#34;\u0026#34; 18# Persistent Volume spec including capacity, access modes, NFS path, and server details follow 19--- 20apiVersion: v1 21kind: PersistentVolumeClaim 22metadata: 23 name: qbitt-download 24 namespace: media 25spec: 26 accessModes: 27 - ReadWriteOnce 28 resources: 29 requests: 30 storage: 400Gi 31 volumeName: qbitt-download 32 storageClassName: \u0026#34;\u0026#34; 33# Persistent Volume Claim spec including access modes, resources requests, and storage class name follow Apply with: kubectl apply -f nfs-download-pv-and-pvc.yaml\nConfiguring Longhorn PVC for Each Application # Create app-config-pvc.yaml:\n1apiVersion: v1 2kind: PersistentVolumeClaim 3metadata: 4 name: app # radarr for example 5 namespace: media 6spec: 7 accessModes: 8 - ReadWriteOnce 9 storageClassName: longhorn 10 resources: 11 requests: 12 storage: 5Gi 13# Persistent Volume Claim spec including access modes, storage class name, and resources requests follow Apply with: kubectl apply -f app-config-pvc.yaml\nThis type of configuration needs to be generated for each application: Jellyfin, Sonarr, Radarr, Jackett, qBittorrent. Deploying each application # Jellyfin # Jellyfin serves as our media streaming platform, providing access to movies, TV shows, and other media across various devices. Here\u0026rsquo;s how to deploy it\nCreate specific yaml for each file, for example: radarr-deployment.yaml Apply with\nkubectl apply -f radarr-deployment.yaml 1apiVersion: apps/v1 2kind: Deployment 3metadata: 4 name: jellyfin 5 namespace: media 6spec: 7 replicas: 1 8 selector: 9 matchLabels: 10 app: jellyfin 11 template: 12 metadata: 13 labels: 14 app: jellyfin 15 spec: 16 containers: 17 - name: jellyfin 18 image: jellyfin/jellyfin 19 volumeMounts: 20 - name: config 21 mountPath: /config 22 - name: videos 23 mountPath: /data/videos 24 ports: 25 - containerPort: 8096 26 volumes: 27 - name: config 28 persistentVolumeClaim: 29 claimName: jellyfin-config 30 - name: videos 31 persistentVolumeClaim: 32 claimName: jellyfin-videos Sonarr # Sonarr automates TV show downloads, managing our series collection efficiently.\n1apiVersion: apps/v1 2kind: Deployment 3metadata: 4 name: sonarr 5 namespace: media 6spec: 7 replicas: 1 8 selector: 9 matchLabels: 10 app: sonarr 11 template: 12 metadata: 13 labels: 14 app: sonarr 15 spec: 16 containers: 17 - name: sonarr 18 image: linuxserver/sonarr 19 env: 20 - name: PUID 21 value: \u0026#34;1057\u0026#34; 22 - name: PGID 23 value: \u0026#34;1056\u0026#34; 24 volumeMounts: 25 - name: config 26 mountPath: /config 27 - name: videos 28 mountPath: /tv 29 - name: downloads 30 mountPath: /downloads 31 ports: 32 - containerPort: 8989 33 volumes: 34 - name: config 35 persistentVolumeClaim: 36 claimName: sonarr-config 37 - name: videos 38 persistentVolumeClaim: 39 claimName: jellyfin-videos 40 - name: downloads 41 persistentVolumeClaim: 42 claimName: qbitt-download Radarr # Radarr works like Sonarr but focuses on movies, keeping our film library organized and up-to-date.\n1apiVersion: apps/v1 2kind: Deployment 3metadata: 4 name: radarr 5 namespace: media 6spec: 7 replicas: 1 8 selector: 9 matchLabels: 10 app: radarr 11 template: 12 metadata: 13 labels: 14 app: radarr 15 spec: 16 containers: 17 - name: radarr 18 image: linuxserver/radarr 19 env: 20 - name: PUID 21 value: \u0026#34;1057\u0026#34; 22 - name: PGID 23 value: \u0026#34;1056\u0026#34; 24 volumeMounts: 25 - name: config 26 mountPath: /config 27 - name: videos 28 mountPath: /movies 29 - name: downloads 30 mountPath: /downloads 31 ports: 32 - containerPort: 7878 33 volumes: 34 - name: config 35 persistentVolumeClaim: 36 claimName: radarr-config 37 - name: videos 38 persistentVolumeClaim: 39 claimName: jellyfin-videos 40 - name: downloads 41 persistentVolumeClaim: 42 claimName: qbitt-download Jackett # Jackett acts as a bridge between torrent search engines and our media management tools, enhancing their capabilities.\n1apiVersion: apps/v1 2kind: Deployment 3metadata: 4 name: jackett 5 namespace: media 6spec: 7 replicas: 1 8 selector: 9 matchLabels: 10 app: jackett 11 template: 12 metadata: 13 labels: 14 app: jackett 15 spec: 16 containers: 17 - name: jackett 18 image: linuxserver/jackett 19 env: 20 - name: PUID 21 value: \u0026#34;1057\u0026#34; 22 - name: PGID 23 value: \u0026#34;1056\u0026#34; 24 volumeMounts: 25 - name: config 26 mountPath: /config 27 ports: 28 - containerPort: 9117 29 volumes: 30 - name: config 31 persistentVolumeClaim: 32 claimName: jackett-config qBittorrent # 1apiVersion: apps/v1 2kind: Deployment 3metadata: 4 name: qbittorrent 5 namespace: media 6spec: 7 replicas: 1 8 selector: 9 matchLabels: 10 app: qbittorrent 11 template: 12 metadata: 13 labels: 14 app: qbittorrent 15 spec: 16 containers: 17 - name: qbittorrent 18 image: linuxserver/qbittorrent 19 resources: 20 limits: 21 memory: \u0026#34;2Gi\u0026#34; 22 requests: 23 memory: \u0026#34;512Mi\u0026#34; 24 env: 25 - name: PUID 26 value: \u0026#34;1057\u0026#34; 27 - name: PGID 28 value: \u0026#34;1056\u0026#34; 29 volumeMounts: 30 - name: config 31 mountPath: /config 32 - name: downloads 33 mountPath: /downloads 34 ports: 35 - containerPort: 8080 36 volumes: 37 - name: config 38 persistentVolumeClaim: 39 claimName: qbitt-config 40 - name: downloads 41 persistentVolumeClaim: 42 claimName: qbitt-download qBittorrent with Gluetun # 1apiVersion: apps/v1 2kind: Deployment 3metadata: 4 name: qbittorrent 5 namespace: media 6spec: 7 replicas: 1 8 selector: 9 matchLabels: 10 app: qbittorrent 11 template: 12 metadata: 13 labels: 14 app: qbittorrent 15 spec: 16 containers: 17 - name: qbittorrent 18 image: linuxserver/qbittorrent 19 resources: 20 limits: 21 memory: \u0026#34;2Gi\u0026#34; 22 requests: 23 memory: \u0026#34;512Mi\u0026#34; 24 env: 25 - name: PUID 26 value: \u0026#34;1057\u0026#34; 27 - name: PGID 28 value: \u0026#34;1056\u0026#34; 29 volumeMounts: 30 - name: config 31 mountPath: /config 32 - name: downloads 33 mountPath: /downloads 34 ports: 35 - containerPort: 8080 36 37 - name: gluetun 38 image: qmcgaw/gluetun 39 env: 40 - name: VPNSP 41 value: \u0026#34;protonvpn\u0026#34; 42 - name: OPENVPN_USER 43 valueFrom: 44 secretKeyRef: 45 name: protonvpn-secrets 46 key: PROTONVPN_USER 47 - name: OPENVPN_PASSWORD 48 valueFrom: 49 secretKeyRef: 50 name: protonvpn-secrets 51 key: PROTONVPN_PASSWORD 52 - name: COUNTRY 53 value: \u0026#34;Germany\u0026#34; 54 securityContext: 55 capabilities: 56 add: 57 - NET_ADMIN 58 volumeMounts: 59 - name: gluetun-config 60 mountPath: /gluetun 61 62 volumes: 63 - name: config 64 persistentVolumeClaim: 65 claimName: qbitt-config 66 - name: downloads 67 persistentVolumeClaim: 68 claimName: qbitt-download 69 - name: gluetun-config 70 persistentVolumeClaim: 71 claimName: gluetun-config I\u0026rsquo;ve chosen to use ProtonVPN due to their security policy and because they do not collect/store data, but also because of the speeds and diverse settings, all at a very good price Creating ClusterIP Services # For our media server applications to communicate efficiently within the Kubernetes cluster without exposing them directly to the external network, we utilize ClusterIP services.\nTo set this up, we create a app-service.yaml for each application (taking Radarr as an example here):\ncreate app-service.yaml 1apiVersion: v1 2kind: Service 3metadata: 4 name: app #radarr for example 5 namespace: media 6spec: 7 type: ClusterIP 8 ports: 9 - port: 80 10 targetPort: 7878 11 selector: 12 app: app #radarr for example kubectl apply -f app-service.yaml\nCreating middleware for Traefik # For enhanced security and to ensure smooth functioning with Traefik, we define middleware:\nThe middleware, named default-headers-media, is configured in the media namespace. It sets various security headers, including XSS protection and options to prevent MIME sniffing, among others. Create default-headers-media.yaml\n1apiVersion: traefik.containo.us/v1alpha1 2kind: Middleware 3metadata: 4 name: default-headers-media 5 namespace: media 6spec: 7 headers: 8 browserXssFilter: true 9 contentTypeNosniff: true 10 forceSTSHeader: true 11 stsIncludeSubdomains: true 12 stsPreload: true 13 stsSeconds: 15552000 14 customFrameOptionsValue: SAMEORIGIN 15 customRequestHeaders: 16 X-Forwarded-Proto: https Apply with: kubectl apply -f default-headers-media.yaml\nCreating Ingress Route for Each Application # To expose each application securely, we create IngressRoutes using Traefik:\nAn IngressRoute for the application (such as Radarr) is defined, which uses the traefik-external ingress class. It listens on the websecure entry point and routes traffic based on the host (movies.merox.cloud in this example, replace with your domain). The middleware default-headers-media is applied to enhance security. TLS configuration is included, referencing a secret that contains the SSL/TLS certificate. Create app-ingress-route.yaml\n1apiVersion: traefik.containo.us/v1alpha1 2kind: IngressRoute 3metadata: 4 name: app #radarr for example 5 namespace: media 6 annotations: 7 kubernetes.io/ingress.class: traefik-external 8spec: 9 entryPoints: 10 - websecure 11 routes: 12 - match: Host(`movies.merox.cloud`) # change to your domain 13 kind: Rule 14 services: 15 - name: app #radarr for example 16 port: 80 17 - match: Host(`movies.merox.cloud`) # change to your domain 18 kind: Rule 19 services: 20 - name: app #radarr for example 21 port: 80 22 middlewares: 23 - name: default-headers-media 24 tls: 25 secretName: mycert-tls # change to your cert name Apply with: kubectl apply -f app-ingress-route.yaml\nDon\u0026rsquo;t forget: You must create the host declared in your IngressRoute in your DNS server(s). Q\u0026amp;A # Q: Why use a ClusterIP service? A: Because we will be using Traefik as an ingress controller to expose it to the local network/internet with SSL/TLS certificates. Q: Can I download all manifest files from anywhere? A: SURE! The link is at the end of this page :) This concludes the necessary steps and configurations to deploy a resilient media server in a Kubernetes cluster successfully.\nManifest files # Just copy and deploy all you need in no time\nAll manifest files 🔗 ","date":"6 March 2024","externalUrl":null,"permalink":"/blog/kubernetes-media-server/","section":"","summary":"For a long time, I\u0026rsquo;ve been on the hunt for a comprehensive and well-crafted tutorial to deploy a media server on my Kubernetes cluster.","title":"Deploying a Kubernetes-Based Media Server","type":"blog"},{"content":"","date":"6 March 2024","externalUrl":null,"permalink":"/categories/kubernetes/","section":"Categories","summary":"","title":"Kubernetes","type":"categories"},{"content":" Privacy Policy Last updated: October 19, 2024\nThis Privacy Policy describes Our policies and procedures on the collection, use and disclosure of Your information when You use the Service and tells You about Your privacy rights and how the law protects You.\nWe use Your Personal data to provide and improve the Service. By using the Service, You agree to the collection and use of information in accordance with this Privacy Policy. This Privacy Policy has been created with the help of the Free Privacy Policy Generator.\nInterpretation and Definitions Interpretation The words of which the initial letter is capitalized have meanings defined under the following conditions. The following definitions shall have the same meaning regardless of whether they appear in singular or in plural.\nDefinitions For the purposes of this Privacy Policy:\nAccount means a unique account created for You to access our Service or parts of our Service. Affiliate means an entity that controls, is controlled by or is under common control with a party, where \u0026ldquo;control\u0026rdquo; means ownership of 50% or more of the shares, equity interest or other securities entitled to vote for election of directors or other managing authority. Company (referred to as either \u0026ldquo;the Company\u0026rdquo;, \u0026ldquo;We\u0026rdquo;, \u0026ldquo;Us\u0026rdquo; or \u0026ldquo;Our\u0026rdquo; in this Agreement) refers to Merox. Cookies are small files that are placed on Your computer, mobile device or any other device by a website, containing the details of Your browsing history on that website among its many uses. Country refers to: Romania Device means any device that can access the Service such as a computer, a cellphone or a digital tablet. Personal Data is any information that relates to an identified or identifiable individual. Service refers to the Website. Service Provider means any natural or legal person who processes the data on behalf of the Company. It refers to third-party companies or individuals employed by the Company to facilitate the Service, to provide the Service on behalf of the Company, to perform services related to the Service or to assist the Company in analyzing how the Service is used. Usage Data refers to data collected automatically, either generated by the use of the Service or from the Service infrastructure itself (for example, the duration of a page visit). Website refers to Merox, accessible from https://merox.dev You means the individual accessing or using the Service, or the company, or other legal entity on behalf of which such individual is accessing or using the Service, as applicable. Collecting and Using Your Personal Data Types of Data Collected Personal Data While using Our Service, We may ask You to provide Us with certain personally identifiable information that can be used to contact or identify You. Personally identifiable information may include, but is not limited to:\nEmail address Usage Data Usage Data Usage Data is collected automatically when using the Service.\nUsage Data may include information such as Your Device\u0026rsquo;s Internet Protocol address (e.g. IP address), browser type, browser version, the pages of our Service that You visit, the time and date of Your visit, the time spent on those pages, unique device identifiers and other diagnostic data.\nWhen You access the Service by or through a mobile device, We may collect certain information automatically, including, but not limited to, the type of mobile device You use, Your mobile device unique ID, the IP address of Your mobile device, Your mobile operating system, the type of mobile Internet browser You use, unique device identifiers and other diagnostic data.\nWe may also collect information that Your browser sends whenever You visit our Service or when You access the Service by or through a mobile device.\nTracking Technologies and Cookies We use Cookies and similar tracking technologies to track the activity on Our Service and store certain information. Tracking technologies used are beacons, tags, and scripts to collect and track information and to improve and analyze Our Service. The technologies We use may include:\nCookies or Browser Cookies. A cookie is a small file placed on Your Device. You can instruct Your browser to refuse all Cookies or to indicate when a Cookie is being sent. However, if You do not accept Cookies, You may not be able to use some parts of our Service. Unless you have adjusted Your browser setting so that it will refuse Cookies, our Service may use Cookies. Web Beacons. Certain sections of our Service and our emails may contain small electronic files known as web beacons (also referred to as clear gifs, pixel tags, and single-pixel gifs) that permit the Company, for example, to count users who have visited those pages or opened an email and for other related website statistics (for example, recording the popularity of a certain section and verifying system and server integrity). Cookies can be \u0026ldquo;Persistent\u0026rdquo; or \u0026ldquo;Session\u0026rdquo; Cookies. Persistent Cookies remain on Your personal computer or mobile device when You go offline, while Session Cookies are deleted as soon as You close Your web browser.\nWe use both Session and Persistent Cookies for the purposes set out below:\nNecessary / Essential Cookies\nType: Session Cookies Administered by: Us Purpose: These Cookies are essential to provide You with services available through the Website and to enable You to use some of its features. They help to authenticate users and prevent fraudulent use of user accounts. Without these Cookies, the services that You have asked for cannot be provided, and We only use these Cookies to provide You with those services. Cookies Policy / Notice Acceptance Cookies\nType: Persistent Cookies Administered by: Us Purpose: These Cookies identify if users have accepted the use of cookies on the Website. Functionality Cookies\nType: Persistent Cookies Administered by: Us Purpose: These Cookies allow us to remember choices You make when You use the Website, such as remembering your login details or language preference. The purpose of these Cookies is to provide You with a more personal experience and to avoid You having to re-enter your preferences every time You use the Website. For more information about the cookies we use and your choices regarding cookies, please visit our Cookies Policy or the Cookies section of our Privacy Policy.\nUse of Your Personal Data The Company may use Personal Data for the following purposes:\nTo provide and maintain our Service, including to monitor the usage of our Service. To manage Your Account: to manage Your registration as a user of the Service. The Personal Data You provide can give You access to different functionalities of the Service that are available to You as a registered user. For the performance of a contract: the development, compliance and undertaking of the purchase contract for the products, items or services You have purchased or of any other contract with Us through the Service. To contact You: To contact You by email, telephone calls, SMS, or other equivalent forms of electronic communication, such as a mobile application\u0026rsquo;s push notifications regarding updates or informative communications related to the functionalities, products or contracted services, including the security updates, when necessary or reasonable for their implementation. To provide You with news, special offers and general information about other goods, services and events which we offer that are similar to those that you have already purchased or enquired about unless You have opted not to receive such information. To manage Your requests: To attend and manage Your requests to Us. For business transfers: We may use Your information to evaluate or conduct a merger, divestiture, restructuring, reorganization, dissolution, or other sale or transfer of some or all of Our assets, whether as a going concern or as part of bankruptcy, liquidation, or similar proceeding, in which Personal Data held by Us about our Service users is among the assets transferred. For other purposes: We may use Your information for other purposes, such as data analysis, identifying usage trends, determining the effectiveness of our promotional campaigns and to evaluate and improve our Service, products, services, marketing and your experience. We may share Your personal information in the following situations:\nWith Service Providers: We may share Your personal information with Service Providers to monitor and analyze the use of our Service, to contact You. For business transfers: We may share or transfer Your personal information in connection with, or during negotiations of, any merger, sale of Company assets, financing, or acquisition of all or a portion of Our business to another company. With Affiliates: We may share Your information with Our affiliates, in which case we will require those affiliates to honor this Privacy Policy. Affiliates include Our parent company and any other subsidiaries, joint venture partners or other companies that We control or that are under common control with Us. With business partners: We may share Your information with Our business partners to offer You certain products, services or promotions. With other users: when You share personal information or otherwise interact in the public areas with other users, such information may be viewed by all users and may be publicly distributed outside. With Your consent: We may disclose Your personal information for any other purpose with Your consent. Retention of Your Personal Data The Company will retain Your Personal Data only for as long as is necessary for the purposes set out in this Privacy Policy. We will retain and use Your Personal Data to the extent necessary to comply with our legal obligations (for example, if we are required to retain your data to comply with applicable laws), resolve disputes, and enforce our legal agreements and policies.\nThe Company will also retain Usage Data for internal analysis purposes. Usage Data is generally retained for a shorter period of time, except when this data is used to strengthen the security or to improve the functionality of Our Service, or We are legally obligated to retain this data for longer time periods.\nTransfer of Your Personal Data Your information, including Personal Data, is processed at the Company\u0026rsquo;s operating offices and in any other places where the parties involved in the processing are located. It means that this information may be transferred to — and maintained on — computers located outside of Your state, province, country or other governmental jurisdiction where the data protection laws may differ than those from Your jurisdiction.\nYour consent to this Privacy Policy followed by Your submission of such information represents Your agreement to that transfer.\nThe Company will take all steps reasonably necessary to ensure that Your data is treated securely and in accordance with this Privacy Policy and no transfer of Your Personal Data will take place to an organization or a country unless there are adequate controls in place including the security of Your data and other personal information.\nDelete Your Personal Data You have the right to delete or request that We assist in deleting the Personal Data that We have collected about You.\nOur Service may give You the ability to delete certain information about You from within the Service.\nYou may update, amend, or delete Your information at any time by signing in to Your Account, if you have one, and visiting the account settings section that allows you to manage Your personal information. You may also contact Us to request access to, correct, or delete any personal information that You have provided to Us.\nPlease note, however, that We may need to retain certain information when we have a legal obligation or lawful basis to do so.\nDisclosure of Your Personal Data Business Transactions If the Company is involved in a merger, acquisition or asset sale, Your Personal Data may be transferred. We will provide notice before Your Personal Data is transferred and becomes subject to a different Privacy Policy.\nLaw enforcement Under certain circumstances, the Company may be required to disclose Your Personal Data if required to do so by law or in response to valid requests by public authorities (e.g. a court or a government agency).\nOther legal requirements The Company may disclose Your Personal Data in the good faith belief that such action is necessary to:\nComply with a legal obligation Protect and defend the rights or property of the Company Prevent or investigate possible wrongdoing in connection with the Service Protect the personal safety of Users of the Service or the public Protect against legal liability Security of Your Personal Data The security of Your Personal Data is important to Us, but remember that no method of transmission over the Internet, or method of electronic storage is 100% secure. While We strive to use commercially acceptable means to protect Your Personal Data, We cannot guarantee its absolute security.\nLinks to Other Websites Our Service may contain links to other websites that are not operated by Us. If You click on a third party link, You will be directed to that third party\u0026rsquo;s site. We strongly advise You to review the Privacy Policy of every site You visit.\nWe have no control over and assume no responsibility for the content, privacy policies or practices of any third party sites or services.\nChanges to this Privacy Policy We may update Our Privacy Policy from time to time. We will notify You of any changes by posting the new Privacy Policy on this page.\nWe will let You know via email and/or a prominent notice on Our Service, prior to the change becoming effective and update the \u0026ldquo;Last updated\u0026rdquo; date at the top of this Privacy Policy.\nYou are advised to review this Privacy Policy periodically for any changes. Changes to this Privacy Policy are effective when they are posted on this page.\nContact Us If you have any questions about this Privacy Policy, You can contact us:\nBy email: hello@merox.dev ","externalUrl":null,"permalink":"/privacy/","section":"Welcome to Merox.dev","summary":"\u003ch1 class=\"relative group\"\u003ePrivacy Policy \n    \u003cdiv id=\"privacy-policy\" class=\"anchor\"\u003e\u003c/div\u003e\n    \n\u003c/h1\u003e\n\u003cp\u003e\u003cstrong\u003eLast updated: October 19, 2024\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003eThis Privacy Policy describes Our policies and procedures on the collection, use and disclosure of Your information when You use the Service and tells You about Your privacy rights and how the law protects You.\u003c/p\u003e","title":"","type":"page"},{"content":"","externalUrl":null,"permalink":"/series/","section":"Series","summary":"","title":"Series","type":"series"}]